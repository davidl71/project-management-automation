"""
Core ML-Enhanced Task Duration Estimator

Uses Core ML with Neural Engine acceleration for task duration estimation.
Provides faster inference on Apple Silicon devices (M1-M4) compared to MLX.

Features:
- Neural Engine acceleration (2-3x faster than CPU)
- Hybrid approach: statistical + Core ML (when models available)
- Graceful fallback to statistical-only if Core ML unavailable
- Automatic hardware selection (CPU/GPU/Neural Engine)
"""

import json
import logging
import re
from pathlib import Path
from typing import Any, Dict, List, Optional

import numpy as np

from .task_duration_estimator import TaskDurationEstimator

logger = logging.getLogger(__name__)

# Try to import Core ML integration
try:
    from .coreml_integration import (
        CORE_ML_AVAILABLE,
        check_coreml_availability,
        predict_with_coreml,
    )
    CORE_ML_ENABLED = CORE_ML_AVAILABLE
except ImportError:
    CORE_ML_ENABLED = False
    logger.debug("Core ML integration not available")


class CoreMLTaskEstimator(TaskDurationEstimator):
    """
    Enhanced task duration estimator using Core ML with Neural Engine.

    Combines statistical methods (from parent class) with Core ML inference
    for improved estimation accuracy and faster batch processing.

    Benefits:
    - Neural Engine acceleration on M1-M4 chips
    - 2-3x faster inference than CPU
    - Lower power consumption
    - Better batch processing performance
    """

    def __init__(
        self,
        project_root=None,
        use_coreml: bool = True,
        coreml_weight: float = 0.3,
        coreml_model_path: Optional[str] = None,
        compute_units: str = "all",  # "all", "cpu_and_gpu", "cpu_and_ane", "cpu_only"
        use_learning: bool = True,
    ):
        """
        Initialize Core ML-enhanced estimator.

        Args:
            project_root: Project root path (defaults to find_project_root)
            use_coreml: Enable Core ML enhancement (default: True)
            coreml_weight: Weight for Core ML estimate in hybrid (0.0-1.0, default: 0.3)
            coreml_model_path: Path to Core ML model (.mlpackage or .mlmodel)
                              If None, uses statistical-only (no Core ML model available yet)
            compute_units: Preferred compute units (all, cpu_and_gpu, cpu_and_ane, cpu_only)
            use_learning: Enable adaptive learning from past estimates (default: True)
        """
        super().__init__(project_root)
        self.use_coreml = use_coreml and CORE_ML_ENABLED
        self.coreml_weight = max(0.0, min(1.0, coreml_weight))  # Clamp to [0, 1]
        self.statistical_weight = 1.0 - self.coreml_weight
        self.coreml_model_path = coreml_model_path
        self.compute_units = compute_units
        self.use_learning = use_learning

        # Check Core ML availability
        if self.use_coreml:
            availability = check_coreml_availability()
            if not availability.get("coreml_available"):
                logger.warning("Core ML not available, falling back to statistical-only")
                self.use_coreml = False
            elif not availability.get("neural_engine_support"):
                logger.info("Neural Engine not available, Core ML will use CPU/GPU")
            else:
                logger.debug(f"Core ML with Neural Engine support enabled")

        # Initialize learner if enabled
        self.learner = None
        self.adjustment_factors = {}
        if self.use_learning:
            try:
                from .estimation_learner import EstimationLearner
                self.learner = EstimationLearner(project_root)
                self.adjustment_factors = self.learner.get_adjustment_factors()
                if self.adjustment_factors:
                    logger.debug(f"Loaded {len(self.adjustment_factors)} adjustment factors from learning")
            except Exception as e:
                logger.debug(f"Learning not available: {e}")
                self.use_learning = False

        if self.use_coreml:
            logger.debug(f"Core ML enhancement enabled (weight: {self.coreml_weight})")
            if self.coreml_model_path:
                logger.debug(f"Core ML model: {self.coreml_model_path}")
            else:
                logger.debug("No Core ML model specified, using statistical-only (Core ML infrastructure ready)")
        else:
            logger.debug("Core ML enhancement disabled or unavailable")

    def estimate(
        self,
        name: str,
        details: str = "",
        tags: Optional[List[str]] = None,
        priority: str = "medium",
        use_historical: bool = True,
    ) -> dict[str, Any]:
        """
        Estimate task duration with Core ML enhancement.

        Uses hybrid approach:
        - Statistical estimate (from parent class): Historical data + keyword matching
        - Core ML estimate: Neural Engine-accelerated inference (when model available)
        - Combined: Weighted average of both

        Falls back gracefully to statistical-only if Core ML unavailable or no model.

        Returns:
            Dictionary with estimate, confidence, method, and metadata
        """
        # Get base statistical estimate
        base_estimate = super().estimate(name, details, tags, priority, use_historical)

        # If Core ML disabled, unavailable, or no model, return statistical estimate
        if not self.use_coreml or not self.coreml_model_path:
            return base_estimate

        # Get Core ML-enhanced estimate
        coreml_estimate = None
        try:
            coreml_estimate = self._coreml_semantic_estimate(name, details, tags or [], priority)
        except Exception as e:
            logger.debug(f"Core ML estimation failed, using statistical only: {e}")

        # Combine estimates if Core ML estimate available
        if coreml_estimate and coreml_estimate.get('estimate_hours'):
            combined = self._combine_estimates(base_estimate, coreml_estimate)
        else:
            combined = base_estimate

        # Apply learned adjustments if learning enabled
        if self.use_learning and self.adjustment_factors:
            combined = self._apply_learned_adjustments(combined, tags or [], priority)

        return combined

    def _coreml_semantic_estimate(
        self,
        name: str,
        details: str,
        tags: list[str],
        priority: str
    ) -> Optional[Dict[str, Any]]:
        """
        Get Core ML-based semantic estimate.

        Uses trained model coefficients for fast, Neural Engine-compatible estimation.
        Supports both .mlpackage models and coefficient JSON files.
        """
        if not self.coreml_model_path:
            return None

        try:
            model_path = Path(self.coreml_model_path)
            
            # Check if it's a coefficient JSON file
            if model_path.suffix == '.json' or not model_path.exists():
                json_path = model_path.with_suffix('.json') if model_path.suffix != '.json' else model_path
                if json_path.exists():
                    return self._estimate_from_coefficients(name, details, tags, priority, json_path)
            
            # Try Core ML .mlpackage model
            if model_path.suffix in ['.mlpackage', '.mlmodel'] and model_path.exists():
                return self._estimate_from_coreml_model(name, details, tags, priority, model_path)
            
            # Fallback: Try JSON if .mlpackage doesn't exist
            json_path = model_path.with_suffix('.json')
            if json_path.exists():
                return self._estimate_from_coefficients(name, details, tags, priority, json_path)
            
            logger.debug(f"Core ML model not found: {self.coreml_model_path}")
            return None

        except Exception as e:
            logger.debug(f"Core ML estimation error: {e}")
            return None

    def _estimate_from_coefficients(
        self,
        name: str,
        details: str,
        tags: list[str],
        priority: str,
        json_path: Path
    ) -> Optional[Dict[str, Any]]:
        """Estimate using saved model coefficients (fast, Neural Engine compatible)."""
        try:
            # Load coefficients
            with open(json_path) as f:
                model_data = json.load(f)
            
            if model_data.get('type') != 'linear_regression':
                logger.debug(f"Unsupported model type: {model_data.get('type')}")
                return None
            
            coefficients = np.array(model_data['coefficients'])
            intercept = model_data['intercept']
            feature_names = model_data['feature_names']
            
            # Extract features (same as training)
            task = {
                'name': name,
                'details': details,
                'tags': tags,
                'priority': priority,
            }
            
            features_dict = self._extract_features_for_prediction(task)
            feature_vector = np.array([features_dict.get(name, 0.0) for name in feature_names])
            
            # Compute estimate: features @ coefficients + intercept
            estimate_hours = float(np.dot(feature_vector, coefficients) + intercept)
            
            # Ensure reasonable bounds
            estimate_hours = max(0.5, min(estimate_hours, 200.0))
            
            # Calculate confidence based on feature quality
            confidence = 0.7  # Base confidence for coefficient-based model
            
            return {
                "estimate_hours": round(estimate_hours, 1),
                "confidence": confidence,
                "complexity": min(10, max(1, int(estimate_hours / 3))),  # Rough complexity
                "method": "coreml_coefficient_based",
                "lower_bound": round(estimate_hours * 0.7, 1),
                "upper_bound": round(estimate_hours * 1.5, 1),
            }
            
        except Exception as e:
            logger.debug(f"Coefficient-based estimation error: {e}")
            return None

    def _extract_features_for_prediction(self, task: Dict[str, Any]) -> Dict[str, float]:
        """Extract features for prediction (same as training)."""
        name = task.get('name', '') or task.get('content', '')
        details = task.get('details', '') or task.get('long_description', '') or ''
        tags = task.get('tags', [])
        if isinstance(tags, str):
            tags = [t.strip() for t in tags.split(',')]
        priority = task.get('priority', 'medium').lower()
        
        full_text = (name + ' ' + details).lower()
        tags_lower = [t.lower() for t in tags]
        
        return {
            'name_length': float(len(name)),
            'details_length': float(len(details)),
            'word_count': float(len(full_text.split())),
            'char_count': float(len(full_text)),
            'has_auth': 1.0 if any(kw in full_text for kw in ['auth', 'login', 'oauth', 'session']) else 0.0,
            'has_test': 1.0 if any(kw in full_text for kw in ['test', 'spec', 'coverage', 'pytest']) else 0.0,
            'has_refactor': 1.0 if any(kw in full_text for kw in ['refactor', 'restructure', 'reorganize']) else 0.0,
            'has_security': 1.0 if any(kw in full_text for kw in ['security', 'vulnerability', 'encrypt', 'secure']) else 0.0,
            'has_api': 1.0 if any(kw in full_text for kw in ['api', 'endpoint', 'route', 'controller']) else 0.0,
            'has_database': 1.0 if any(kw in full_text for kw in ['database', 'db', 'sql', 'query', 'model']) else 0.0,
            'has_ui': 1.0 if any(kw in full_text for kw in ['ui', 'frontend', 'component', 'page', 'view']) else 0.0,
            'has_integration': 1.0 if any(kw in full_text for kw in ['integrate', 'integration', 'connect', 'sync']) else 0.0,
            'has_fix': 1.0 if any(kw in full_text for kw in ['fix', 'bug', 'error', 'issue', 'resolve']) else 0.0,
            'has_implement': 1.0 if any(kw in full_text for kw in ['implement', 'add', 'create', 'build']) else 0.0,
            'has_complex': 1.0 if any(kw in full_text for kw in ['complex', 'advanced', 'sophisticated', 'intricate']) else 0.0,
            'has_simple': 1.0 if any(kw in full_text for kw in ['simple', 'basic', 'quick', 'easy']) else 0.0,
            'priority_low': 1.0 if priority == 'low' else 0.0,
            'priority_medium': 1.0 if priority == 'medium' else 0.0,
            'priority_high': 1.0 if priority == 'high' else 0.0,
            'priority_critical': 1.0 if priority == 'critical' else 0.0,
            'tag_count': float(len(tags)),
            'has_security_tag': 1.0 if any('security' in t.lower() for t in tags) else 0.0,
            'has_testing_tag': 1.0 if any('test' in t.lower() for t in tags) else 0.0,
            'has_backend_tag': 1.0 if any('backend' in t.lower() for t in tags) else 0.0,
            'has_frontend_tag': 1.0 if any('frontend' in t.lower() for t in tags) else 0.0,
            'has_documentation_tag': 1.0 if any('doc' in t.lower() for t in tags) else 0.0,
            'priority_score': {
                'low': 1.0, 'medium': 2.0, 'high': 3.0, 'critical': 4.0,
            }.get(priority, 2.0),
        }

    def _estimate_from_coreml_model(
        self,
        name: str,
        details: str,
        tags: list[str],
        priority: str,
        model_path: Path
    ) -> Optional[Dict[str, Any]]:
        """Estimate using Core ML .mlpackage model."""
        try:
            tags_str = ", ".join(tags) if tags else "none"
            task_text = f"{name}. {details}. Tags: {tags_str}. Priority: {priority}"

            input_data = {
                "task_text": task_text,
                "name": name,
                "details": details,
                "tags": tags_str,
                "priority": priority,
            }

            result_json = predict_with_coreml(
                model_path=str(model_path),
                input_data=input_data,
                compute_units=self.compute_units,
            )

            result = json.loads(result_json)
            
            if not result.get("success"):
                return None

            predictions = result.get("data", {}).get("predictions", {})
            estimate_hours = predictions.get("estimate_hours") or predictions.get("hours") or predictions.get("duration")
            confidence = predictions.get("confidence", 0.7)
            complexity = predictions.get("complexity", 5)

            if estimate_hours:
                return {
                    "estimate_hours": float(estimate_hours),
                    "confidence": float(confidence),
                    "complexity": int(complexity),
                    "method": "coreml_neural_engine",
                    "lower_bound": float(estimate_hours) * 0.7,
                    "upper_bound": float(estimate_hours) * 1.5,
                }

        except Exception as e:
            logger.debug(f"Core ML model estimation error: {e}")
            return None

        return None

    def _combine_estimates(
        self,
        statistical: Dict[str, Any],
        coreml: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Combine statistical and Core ML estimates using weighted average.

        Args:
            statistical: Statistical estimate from parent class
            coreml: Core ML estimate

        Returns:
            Combined estimate with weighted average
        """
        stat_hours = statistical.get("estimate_hours", 0)
        coreml_hours = coreml.get("estimate_hours", 0)

        # Weighted combination
        combined_hours = (
            self.statistical_weight * stat_hours +
            self.coreml_weight * coreml_hours
        )

        # Combined confidence (weighted average)
        stat_conf = statistical.get("confidence", 0.5)
        coreml_conf = coreml.get("confidence", 0.7)
        combined_confidence = (
            self.statistical_weight * stat_conf +
            self.coreml_weight * coreml_conf
        )

        # Use Core ML complexity if available
        complexity = coreml.get("complexity", statistical.get("complexity", 5))

        return {
            "estimate_hours": round(combined_hours, 1),
            "confidence": round(combined_confidence, 2),
            "method": f"hybrid_statistical_coreml",
            "lower_bound": round(combined_hours * 0.7, 1),
            "upper_bound": round(combined_hours * 1.5, 1),
            "complexity": complexity,
            "statistical_estimate": stat_hours,
            "coreml_estimate": coreml_hours,
            "weights": {
                "statistical": self.statistical_weight,
                "coreml": self.coreml_weight,
            },
        }

    def _apply_learned_adjustments(
        self,
        estimate: Dict[str, Any],
        tags: List[str],
        priority: str
    ) -> Dict[str, Any]:
        """Apply learned adjustments from past estimation accuracy."""
        if not self.adjustment_factors:
            return estimate

        # Find matching adjustment factors
        adjustment = 1.0
        for factor in self.adjustment_factors.values():
            # Match by tags or priority
            if factor.get("tags") and any(tag in tags for tag in factor.get("tags", [])):
                adjustment *= factor.get("adjustment", 1.0)
            elif factor.get("priority") == priority:
                adjustment *= factor.get("adjustment", 1.0)

        if adjustment != 1.0:
            original_hours = estimate.get("estimate_hours", 0)
            adjusted_hours = original_hours * adjustment
            estimate["estimate_hours"] = round(adjusted_hours, 1)
            estimate["lower_bound"] = round(adjusted_hours * 0.7, 1)
            estimate["upper_bound"] = round(adjusted_hours * 1.5, 1)
            estimate["learned_adjustment"] = adjustment

        return estimate


def estimate_task_duration_coreml_enhanced(
    name: str,
    details: str = "",
    tags: Optional[List[str]] = None,
    priority: str = "medium",
    use_historical: bool = True,
    use_coreml: bool = True,
    coreml_weight: float = 0.3,
    coreml_model_path: Optional[str] = None,
    compute_units: str = "all",
) -> float:
    """
    Quick function to get Core ML-enhanced task duration estimate.

    Returns just the hours estimate (float) for simple use cases.

    Args:
        name: Task name
        details: Task details/description
        tags: Task tags
        priority: Task priority (low, medium, high, critical)
        use_historical: Use historical data
        use_coreml: Enable Core ML enhancement
        coreml_weight: Weight for Core ML estimate (0.0-1.0)
        coreml_model_path: Path to Core ML model
        compute_units: Core ML compute units preference

    Returns:
        Estimated hours (float)
    """
    estimator = CoreMLTaskEstimator(
        use_coreml=use_coreml,
        coreml_weight=coreml_weight,
        coreml_model_path=coreml_model_path,
        compute_units=compute_units,
    )

    result = estimator.estimate(
        name=name,
        details=details,
        tags=tags or [],
        priority=priority,
        use_historical=use_historical,
    )

    return result.get("estimate_hours", 0.0)


def estimate_task_duration_coreml_enhanced_detailed(
    name: str,
    details: str = "",
    tags: Optional[List[str]] = None,
    priority: str = "medium",
    use_historical: bool = True,
    use_coreml: bool = True,
    coreml_weight: float = 0.3,
    coreml_model_path: Optional[str] = None,
    compute_units: str = "all",
) -> Dict[str, Any]:
    """
    Get detailed Core ML-enhanced task duration estimate.

    Returns full dictionary with estimate, confidence, method, and metadata.

    Args:
        name: Task name
        details: Task details/description
        tags: Task tags
        priority: Task priority (low, medium, high, critical)
        use_historical: Use historical data
        use_coreml: Enable Core ML enhancement
        coreml_weight: Weight for Core ML estimate (0.0-1.0)
        coreml_model_path: Path to Core ML model
        compute_units: Core ML compute units preference

    Returns:
        Dictionary with estimate details
    """
    estimator = CoreMLTaskEstimator(
        use_coreml=use_coreml,
        coreml_weight=coreml_weight,
        coreml_model_path=coreml_model_path,
        compute_units=compute_units,
    )

    return estimator.estimate(
        name=name,
        details=details,
        tags=tags or [],
        priority=priority,
        use_historical=use_historical,
    )

