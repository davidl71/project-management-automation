#!/usr/bin/env python3
"""
Comprehensive test script for basic Ollama integration tools.

Tests all basic Ollama integration functions:
- check_ollama_status
- list_ollama_models
- generate_with_ollama
- get_hardware_info
- pull_ollama_model (if needed)

Run with: uv run python test_ollama_basic_integration.py
"""

import json
import sys
import time
from pathlib import Path

# Add project root to path
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

def test_check_status():
    """Test check_ollama_status function."""
    print("\n" + "="*60)
    print("TEST 1: check_ollama_status")
    print("="*60)
    
    try:
        from project_management_automation.tools.ollama_integration import check_ollama_status
        
        result_str = check_ollama_status()
        result = json.loads(result_str)
        
        print(f"‚úÖ Status: {result.get('success')}")
        if result.get('success'):
            data = result.get('data', {})
            print(f"   Server status: {data.get('status')}")
            print(f"   Host: {data.get('host')}")
            print(f"   Model count: {data.get('model_count')}")
            print(f"   Models: {data.get('models')}")
        else:
            print(f"   Error: {result.get('error', {}).get('message', 'Unknown error')}")
        
        return result.get('success') == True
    except Exception as e:
        print(f"‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_list_models():
    """Test list_ollama_models function."""
    print("\n" + "="*60)
    print("TEST 2: list_ollama_models")
    print("="*60)
    
    try:
        from project_management_automation.tools.ollama_integration import list_ollama_models
        
        result_str = list_ollama_models()
        result = json.loads(result_str)
        
        print(f"‚úÖ Status: {result.get('success')}")
        if result.get('success'):
            data = result.get('data', {})
            models = data.get('models', [])
            print(f"   Model count: {data.get('count', 0)}")
            print(f"   Models:")
            for model in models[:5]:  # Show first 5
                print(f"     - {model.get('name', 'Unknown')} ({model.get('size', 0) / (1024**3):.2f} GB)")
        else:
            print(f"   Error: {result.get('error', {}).get('message', 'Unknown error')}")
        
        return result.get('success') == True
    except Exception as e:
        print(f"‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_hardware_info():
    """Test get_hardware_info function."""
    print("\n" + "="*60)
    print("TEST 3: get_hardware_info")
    print("="*60)
    
    try:
        from project_management_automation.tools.ollama_integration import get_hardware_info
        
        result_str = get_hardware_info()
        result = json.loads(result_str)
        
        print(f"‚úÖ Status: {result.get('success')}")
        if result.get('success'):
            data = result.get('data', {})
            print(f"   Platform: {data.get('platform')}")
            print(f"   Architecture: {data.get('architecture')}")
            print(f"   CPU cores: {data.get('cpu_cores')}")
            print(f"   RAM: {data.get('ram_gb')} GB")
            print(f"   GPU available: {data.get('gpu_available')}")
            print(f"   GPU type: {data.get('gpu_type')}")
            
            rec = data.get('recommended_settings', {})
            print(f"   Recommended:")
            print(f"     - Threads: {rec.get('num_threads')}")
            print(f"     - GPU layers: {rec.get('num_gpu')}")
            print(f"     - Context size: {rec.get('context_size')}")
        else:
            print(f"   Error: {result.get('error', {}).get('message', 'Unknown error')}")
        
        return result.get('success') == True
    except Exception as e:
        print(f"‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_generate_text():
    """Test generate_with_ollama function with a simple prompt."""
    print("\n" + "="*60)
    print("TEST 4: generate_with_ollama (short prompt)")
    print("="*60)
    
    try:
        from project_management_automation.tools.ollama_integration import generate_with_ollama
        
        prompt = "Write a one-sentence Python function to add two numbers."
        model = "llama3.2"  # Use small model for quick test
        
        print(f"Prompt: {prompt}")
        print(f"Model: {model}")
        print("Generating... (this may take 10-30 seconds)")
        
        start_time = time.time()
        result_str = generate_with_ollama(
            prompt=prompt,
            model=model,
            stream=False,  # Disable streaming for simplicity
        )
        duration = time.time() - start_time
        
        result = json.loads(result_str)
        
        print(f"‚úÖ Status: {result.get('success')}")
        print(f"   Duration: {duration:.2f} seconds")
        
        if result.get('success'):
            data = result.get('data', {})
            response = data.get('response', '')
            print(f"   Response length: {len(response)} characters")
            print(f"   Response preview: {response[:100]}...")
            
            perf = data.get('performance_options', {})
            if perf:
                print(f"   Performance options:")
                print(f"     - GPU layers: {perf.get('num_gpu')}")
                print(f"     - CPU threads: {perf.get('num_threads')}")
                print(f"     - Context size: {perf.get('context_size')}")
        else:
            print(f"   Error: {result.get('error', {}).get('message', 'Unknown error')}")
        
        return result.get('success') == True
    except Exception as e:
        print(f"‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_error_handling():
    """Test error handling for common failure scenarios."""
    print("\n" + "="*60)
    print("TEST 5: Error Handling")
    print("="*60)
    
    try:
        from project_management_automation.tools.ollama_integration import generate_with_ollama
        
        # Test with non-existent model
        print("Testing with non-existent model...")
        result_str = generate_with_ollama(
            prompt="Test",
            model="nonexistent-model-12345",
        )
        result = json.loads(result_str)
        
        if not result.get('success'):
            error_msg = result.get('error', {}).get('message', '')
            print(f"‚úÖ Correctly handled error: {error_msg[:100]}")
            return True
        else:
            print("‚ùå Expected error but got success")
            return False
            
    except Exception as e:
        print(f"‚ö†Ô∏è  Exception during error test: {e}")
        # This might be acceptable if error handling catches it
        return True  # Don't fail the whole test suite


def main():
    """Run all tests."""
    print("="*60)
    print("Ollama Basic Integration Test Suite")
    print("="*60)
    print("\nPrerequisites:")
    print("- Ollama server should be running")
    print("- At least one model should be installed (llama3.2 recommended)")
    print()
    
    results = []
    
    # Run tests
    results.append(("check_ollama_status", test_check_status()))
    results.append(("list_ollama_models", test_list_models()))
    results.append(("get_hardware_info", test_hardware_info()))
    results.append(("generate_with_ollama", test_generate_text()))
    results.append(("error_handling", test_error_handling()))
    
    # Print summary
    print("\n" + "="*60)
    print("TEST SUMMARY")
    print("="*60)
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for test_name, result in results:
        status = "‚úÖ PASS" if result else "‚ùå FAIL"
        print(f"{status}: {test_name}")
    
    print(f"\nTotal: {passed}/{total} tests passed")
    
    if passed == total:
        print("\nüéâ All tests passed!")
        return 0
    else:
        print(f"\n‚ö†Ô∏è  {total - passed} test(s) failed")
        return 1


if __name__ == "__main__":
    sys.exit(main())

